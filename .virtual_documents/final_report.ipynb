import warnings
warnings.filterwarnings('ignore')

import pandas as pd
import numpy as np


import wrangle as w
import explore as ex
import model as m


import seaborn as sns
import matplotlib.pyplot as plt
from scipy import stats

from sklearn.feature_selection import f_regression 
from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor
from sklearn.feature_selection import RFE, SelectKBest, f_regression
from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score
from sklearn.metrics import r2_score


# retrieve the data from database or directory 
df = w.get_data()
dfpool.is_null()


# clean data, remove nulls, outliers and rename columns
df = w.clean_zillow()


# split the data into train, validate, test
train, validate, test = w.split_data(df)


# overview of data
train.head()


ex.create_relplot(x_var="area", y_var="property_value", df=train)


ex.bathroom_barplot(train)


avg_full_bath  = train[train.full_bath == 1].property_value
avg_half_bath = train[train.full_bath == 0].property_value


ex.ind_test(avg_half_bath, avg_full_bath)


ex.pool_barplot(train)


yes_pool  = train[train.pool == 1].property_value
no_pool = train[train.pool == 0].property_value


ex.ind_test(yes_pool, no_pool)


ex.county_barplot(train)


orange_sample = train[train.fips == 'Orange'].property_value
overall_mean = train.property_value.mean()


ex.one_test(orange_sample, overall_mean)


# features and the target variable
features = ['area', 'bathrooms', 'bedroom', 'year', 'pool', 'full_bath','orange', 'ventura']
target = "property_value"

# split the train, validate, test into x and y 
x_train, x_validate, x_test  = train[features], validate[features], test[features]
y_train, y_validate, y_test = train[target], validate[target], test[target]

# scaling the x datasets
x_train_scaled, x_validate_scaled, x_test_scaled = w.mm_scale(x_train, x_validate, x_test)


# creating and adding the baseline
baseline = y_train.mean()
baseline_array = np.repeat(baseline, len(train))
rmse, r2 = m.metrics_reg(y_train, baseline_array)

# metrics dataframe
metrics_df = pd.DataFrame(data=[{'model':'baseline', 'rmse':rmse,'r2':r2}])
metrics_df


# Display the plot
sns.histplot(data=y_train)
plt.xlabel("Property Value")
plt.show()


x_train_scaled


# make the model, fit and use it on train and validate
ols_rmse, ols_r2 = m.ols_mod(x_train_scaled, x_validate_scaled, y_train, y_validate)
# add to metrics_reg
metrics_df.loc[1] = ['ols', ols_rmse, ols_r2]


lars_rmse, lars_r2 = m.lars_mod(x_train_scaled, x_validate_scaled, y_train, y_validate)
metrics_df.loc[2] = ['lars', lars_rmse, lars_r2]


glm_rmse, glm_r2 = m.glm_mod(x_train_scaled, x_validate_scaled, y_train, y_validate)
metrics_df.loc[3] = ['glm', glm_rmse, glm_r2]


ploy_rmse, ploy_r2 = m.poly_mod(x_train_scaled, x_validate_scaled, x_test_scaled, y_train, y_validate)
metrics_df.loc[4] = ['poly', ploy_rmse, ploy_r2]


metrics_df


test_rmse, test_r2 = m.best_model(x_train_scaled, x_test_scaled, y_train, y_test)
metrics_df.loc[5] = ['final test', test_rmse, test_r2]


metrics_df.loc[4:]
